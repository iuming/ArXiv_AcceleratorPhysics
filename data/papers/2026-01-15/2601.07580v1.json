{
  "arxiv_id": "2601.07580v1",
  "url": "https://arxiv.org/abs/2601.07580v1",
  "pdf_url": "https://arxiv.org/pdf/2601.07580v1.pdf",
  "title": "Large Language Models for Physics Instrument Design",
  "abstract": "We study the use of large language models (LLMs) for physics instrument design and compare their performance to reinforcement learning (RL). Using only prompting, LLMs are given task constraints and summaries of prior high-scoring designs and propose complete detector configurations, which we evaluate with the same simulators and reward functions used in RL-based optimization. Although RL yields stronger final designs, we find that modern LLMs consistently generate valid, resource-aware, and physically meaningful configurations that draw on broad pretrained knowledge of detector design principles and particle--matter interactions, despite having no task-specific training. Based on this result, as a first step toward hybrid design workflows, we explore pairing the LLMs with a dedicated trust region optimizer, serving as a precursor to future pipelines in which LLMs propose and structure design hypotheses while RL performs reward-driven optimization. Based on these experiments, we argue that LLMs are well suited as meta-planners: they can design and orchestrate RL-based optimization studies, define search strategies, and coordinate multiple interacting components within a unified workflow. In doing so, they point toward automated, closed-loop instrument design in which much of the human effort required to structure and supervise optimization can be reduced.",
  "authors": [
    "Sara Zoccheddu",
    "Shah Rukh Qasim",
    "Patrick Owen",
    "Nicola Serra"
  ],
  "published": "2026-01-12T14:30:54Z",
  "updated": "2026-01-12T14:30:54Z",
  "categories": [
    "physics.ins-det",
    "cs.AI",
    "cs.LG",
    "hep-ex"
  ],
  "primary_category": "physics.ins-det"
}