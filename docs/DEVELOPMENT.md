# å¼€å‘æŒ‡å—

æœ¬æ–‡æ¡£ä¸ºé¡¹ç›®å¼€å‘è€…æä¾›è¯¦ç»†çš„å¼€å‘æŒ‡å—å’Œæœ€ä½³å®è·µã€‚

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

### æ€»ä½“æ¶æ„
```
ArXiv_AcceleratorPhysics/
â”œâ”€â”€ src/                    # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ main.py            # ä¸»ç¨‹åºå…¥å£
â”‚   â”œâ”€â”€ arxiv_fetcher.py   # ArXivæ•°æ®æŠ“å–
â”‚   â”œâ”€â”€ llm_analyzer.py    # LLMåˆ†æå¼•æ“
â”‚   â”œâ”€â”€ data_processor.py  # æ•°æ®å¤„ç†
â”‚   â””â”€â”€ utils.py           # é€šç”¨å·¥å…·
â”œâ”€â”€ templates/             # æç¤ºæ¨¡æ¿
â”œâ”€â”€ config/                # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/                  # æ•°æ®å­˜å‚¨
â””â”€â”€ tests/                 # æµ‹è¯•ä»£ç 
```

### æ¨¡å—èŒè´£

#### `main.py`
- ç¨‹åºå…¥å£ç‚¹
- åè°ƒå„æ¨¡å—å·¥ä½œæµç¨‹
- é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

#### `arxiv_fetcher.py`
- ArXiv APIé›†æˆ
- è®ºæ–‡æ•°æ®æŠ“å–
- æ•°æ®æ¸…æ´—å’ŒéªŒè¯

#### `llm_analyzer.py`
- å¤šLLMæœåŠ¡æ”¯æŒ
- è®ºæ–‡å†…å®¹åˆ†æ
- ç»“æœåå¤„ç†

#### `data_processor.py`
- æ•°æ®å­˜å‚¨ç®¡ç†
- ç»Ÿè®¡åˆ†æ
- æŠ¥å‘Šç”Ÿæˆ

#### `utils.py`
- é€šç”¨å·¥å…·å‡½æ•°
- é…ç½®ç®¡ç†
- æ—¥å¿—è®¾ç½®

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒè®¾ç½®

### 1. ç¯å¢ƒè¦æ±‚
- Python 3.8+
- Git
- æ–‡æœ¬ç¼–è¾‘å™¨/IDE (æ¨èVS Code)

### 2. å…‹éš†å’Œè®¾ç½®
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/iuming/ArXiv_AcceleratorPhysics.git
cd ArXiv_AcceleratorPhysics

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt  # å¼€å‘ä¾èµ–
```

### 3. å¼€å‘å·¥å…·é…ç½®

#### VS Codeè®¾ç½®
æ¨èçš„VS Codeæ‰©å±•ï¼š
- Python
- Pylance
- Python Docstring Generator
- GitLens
- Black Formatter

#### `.vscode/settings.json`
```json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "python.formatting.provider": "black",
    "python.sortImports.args": ["--profile", "black"],
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    }
}
```

## ğŸ“ ä»£ç è§„èŒƒ

### ä»£ç é£æ ¼
- éµå¾ªPEP 8
- ä½¿ç”¨Blackè¿›è¡Œä»£ç æ ¼å¼åŒ–
- ä½¿ç”¨isortè¿›è¡Œimportæ’åº
- è¡Œé•¿åº¦é™åˆ¶ä¸º88å­—ç¬¦

### å‘½åçº¦å®š
- **ç±»å**: PascalCase (`ArXivFetcher`)
- **å‡½æ•°/å˜é‡**: snake_case (`fetch_papers`)
- **å¸¸é‡**: UPPER_SNAKE_CASE (`MAX_RETRIES`)
- **ç§æœ‰æ–¹æ³•**: å‰ç¼€ä¸‹åˆ’çº¿ (`_parse_response`)

### æ–‡æ¡£å­—ç¬¦ä¸²
ä½¿ç”¨Googleé£æ ¼çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼š

```python
def fetch_papers(self, days_back: int = 1) -> List[Dict]:
    """æŠ“å–æœ€è¿‘çš„è®ºæ–‡æ•°æ®.
    
    Args:
        days_back: å›æº¯å¤©æ•°ï¼Œé»˜è®¤ä¸º1å¤©
        
    Returns:
        åŒ…å«è®ºæ–‡ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        
    Raises:
        APIError: å½“APIè°ƒç”¨å¤±è´¥æ—¶
        ValidationError: å½“æ•°æ®éªŒè¯å¤±è´¥æ—¶
        
    Example:
        >>> fetcher = ArXivFetcher(config)
        >>> papers = await fetcher.fetch_papers(2)
        >>> len(papers)
        15
    """
```

### ç±»å‹æç¤º
æ‰€æœ‰å‡½æ•°éƒ½åº”è¯¥æœ‰ç±»å‹æç¤ºï¼š

```python
from typing import Dict, List, Optional, Union, Any
import asyncio

async def process_papers(
    papers: List[Dict[str, Any]], 
    config: Dict[str, Union[str, int]]
) -> Optional[Dict[str, Any]]:
    """å¤„ç†è®ºæ–‡æ•°æ®."""
    pass
```

## ğŸ§ª æµ‹è¯•

### æµ‹è¯•ç»“æ„
```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_arxiv_fetcher.py
â”œâ”€â”€ test_llm_analyzer.py
â”œâ”€â”€ test_data_processor.py
â”œâ”€â”€ test_utils.py
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ sample_papers.json
â”‚   â””â”€â”€ sample_config.yaml
â””â”€â”€ integration/
    â””â”€â”€ test_full_workflow.py
```

### å•å…ƒæµ‹è¯•ç¤ºä¾‹
```python
import pytest
import asyncio
from unittest.mock import Mock, patch
from src.arxiv_fetcher import ArXivFetcher

class TestArXivFetcher:
    """ArXivFetcheræµ‹è¯•ç±»."""
    
    @pytest.fixture
    def config(self):
        """æµ‹è¯•é…ç½®."""
        return {
            "max_papers_per_day": 10,
            "category": "physics.acc-ph"
        }
    
    @pytest.fixture
    def fetcher(self, config):
        """ArXivFetcherå®ä¾‹."""
        return ArXivFetcher(config)
    
    @pytest.mark.asyncio
    async def test_fetch_papers_success(self, fetcher):
        """æµ‹è¯•æˆåŠŸæŠ“å–è®ºæ–‡."""
        with patch('aiohttp.ClientSession.get') as mock_get:
            # Mock APIå“åº”
            mock_response = Mock()
            mock_response.text.return_value = asyncio.coroutine(
                lambda: self._get_sample_xml()
            )()
            mock_get.return_value.__aenter__.return_value = mock_response
            
            papers = await fetcher.fetch_papers()
            
            assert len(papers) > 0
            assert 'title' in papers[0]
            assert 'abstract' in papers[0]
    
    def _get_sample_xml(self):
        """è¿”å›ç¤ºä¾‹XMLå“åº”."""
        return """<?xml version="1.0" encoding="UTF-8"?>
        <feed>
            <entry>
                <title>Sample Paper</title>
                <summary>Sample abstract</summary>
            </entry>
        </feed>"""
```

### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_arxiv_fetcher.py

# è¿è¡Œè¦†ç›–ç‡æµ‹è¯•
pytest --cov=src --cov-report=html

# è¿è¡Œç‰¹å®šæ ‡è®°çš„æµ‹è¯•
pytest -m "not slow"
```

## ğŸ”„ å¼‚æ­¥ç¼–ç¨‹

### å¼‚æ­¥æœ€ä½³å®è·µ
```python
import asyncio
import aiohttp
from typing import List, Dict

class AsyncProcessor:
    """å¼‚æ­¥å¤„ç†å™¨ç¤ºä¾‹."""
    
    def __init__(self):
        self.session = None
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£."""
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£."""
        if self.session:
            await self.session.close()
    
    async def process_batch(self, items: List[Dict]) -> List[Dict]:
        """å¹¶å‘å¤„ç†æ‰¹æ¬¡æ•°æ®."""
        tasks = [self._process_item(item) for item in items]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"å¤„ç†å¤±è´¥: {result}")
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _process_item(self, item: Dict) -> Dict:
        """å¤„ç†å•ä¸ªé¡¹ç›®."""
        # æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†
        await asyncio.sleep(0.1)
        return {"processed": item}

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    async with AsyncProcessor() as processor:
        results = await processor.process_batch(items)
    return results
```

## ğŸ”§ é…ç½®ç®¡ç†

### é…ç½®ç»“æ„
```yaml
# config/settings.yaml
app:
  name: "ArXiv_AcceleratorPhysics"
  version: "1.0.0"
  
arxiv:
  base_url: "http://export.arxiv.org/api/query"
  category: "physics.acc-ph"
  max_papers_per_day: 20
  retry_count: 3
  timeout: 30

llm:
  providers:
    - name: "deepseek"
      enabled: true
      model: "deepseek-chat"
      max_tokens: 4096
    - name: "openai"
      enabled: false
      model: "gpt-4"
      max_tokens: 4096

storage:
  base_path: "data"
  compression: true
  backup_count: 7

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/arxiv_analysis.log"
```

### é…ç½®åŠ è½½
```python
import yaml
from pathlib import Path
from typing import Dict, Any

def load_config(config_path: str = "config/settings.yaml") -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶."""
    config_file = Path(config_path)
    
    if not config_file.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ç¯å¢ƒå˜é‡è¦†ç›–
    config = _apply_env_overrides(config)
    
    return config

def _apply_env_overrides(config: Dict[str, Any]) -> Dict[str, Any]:
    """åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–."""
    import os
    
    # ç¤ºä¾‹ï¼šARXIV_MAX_PAPERS -> config.arxiv.max_papers_per_day
    env_mappings = {
        'ARXIV_MAX_PAPERS': ('arxiv', 'max_papers_per_day'),
        'LLM_PROVIDER': ('llm', 'default_provider'),
    }
    
    for env_key, (section, key) in env_mappings.items():
        if env_value := os.getenv(env_key):
            config[section][key] = env_value
    
    return config
```

## ğŸš¦ é”™è¯¯å¤„ç†

### è‡ªå®šä¹‰å¼‚å¸¸
```python
class ArXivError(Exception):
    """ArXivç›¸å…³é”™è¯¯åŸºç±»."""
    pass

class APIError(ArXivError):
    """APIè°ƒç”¨é”™è¯¯."""
    
    def __init__(self, message: str, status_code: int = None):
        super().__init__(message)
        self.status_code = status_code

class ValidationError(ArXivError):
    """æ•°æ®éªŒè¯é”™è¯¯."""
    pass

class ProcessingError(ArXivError):
    """æ•°æ®å¤„ç†é”™è¯¯."""
    pass
```

### é”™è¯¯å¤„ç†æ¨¡å¼
```python
import logging
from typing import Optional, Dict, Any
from functools import wraps

logger = logging.getLogger(__name__)

def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    """é‡è¯•è£…é¥°å™¨."""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        logger.warning(
                            f"ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}, "
                            f"{delay}ç§’åé‡è¯•..."
                        )
                        await asyncio.sleep(delay * (2 ** attempt))
                    else:
                        logger.error(f"æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†: {e}")
            
            raise last_exception
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@retry_on_failure(max_retries=3, delay=2.0)
async def fetch_with_retry(url: str) -> Dict[str, Any]:
    """å¸¦é‡è¯•çš„æ•°æ®æŠ“å–."""
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            if response.status != 200:
                raise APIError(f"HTTP {response.status}", response.status)
            return await response.json()
```

## ğŸ“Š æ—¥å¿—è®°å½•

### æ—¥å¿—é…ç½®
```python
import logging
import logging.handlers
from pathlib import Path

def setup_logging(
    level: str = "INFO",
    log_file: str = "logs/arxiv_analysis.log",
    max_bytes: int = 10 * 1024 * 1024,  # 10MB
    backup_count: int = 5
) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—è®°å½•."""
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_path = Path(log_file)
    log_path.parent.mkdir(exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - '
        '%(filename)s:%(lineno)d - %(message)s'
    )
    
    # æ ¹æ—¥å¿—å™¨
    logger = logging.getLogger()
    logger.setLevel(getattr(logging, level.upper()))
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆè½®è½¬ï¼‰
    file_handler = logging.handlers.RotatingFileHandler(
        log_file, maxBytes=max_bytes, backupCount=backup_count,
        encoding='utf-8'
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger

# ä½¿ç”¨ç¤ºä¾‹
logger = setup_logging()

class Component:
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def process(self):
        self.logger.info("å¼€å§‹å¤„ç†...")
        try:
            # å¤„ç†é€»è¾‘
            self.logger.debug("å¤„ç†è¯¦ç»†ä¿¡æ¯...")
            result = self._do_work()
            self.logger.info(f"å¤„ç†å®Œæˆï¼Œç»“æœ: {result}")
            return result
        except Exception as e:
            self.logger.error(f"å¤„ç†å¤±è´¥: {e}", exc_info=True)
            raise
```

## ğŸ”„ Gitå·¥ä½œæµç¨‹

### åˆ†æ”¯ç­–ç•¥
- `main`: ç¨³å®šçš„ç”Ÿäº§ä»£ç 
- `develop`: å¼€å‘åˆ†æ”¯
- `feature/feature-name`: åŠŸèƒ½åˆ†æ”¯
- `hotfix/issue-description`: ç´§æ€¥ä¿®å¤

### æäº¤è§„èŒƒ
```bash
# åŠŸèƒ½æäº¤
git commit -m "feat(analyzer): add DeepSeek API support"

# Bugä¿®å¤
git commit -m "fix(fetcher): handle rate limit errors"

# æ–‡æ¡£æ›´æ–°
git commit -m "docs: update API setup guide"

# é‡æ„
git commit -m "refactor(processor): optimize data storage"
```

### å‘å¸ƒæµç¨‹
```bash
# 1. ç¡®ä¿åœ¨developåˆ†æ”¯
git checkout develop
git pull origin develop

# 2. åˆ›å»ºå‘å¸ƒåˆ†æ”¯
git checkout -b release/1.1.0

# 3. æ›´æ–°ç‰ˆæœ¬å·å’Œæ–‡æ¡£
# ç¼–è¾‘setup.py, __init__.pyç­‰æ–‡ä»¶

# 4. æäº¤å‘å¸ƒå‡†å¤‡
git commit -m "chore: prepare release 1.1.0"

# 5. åˆå¹¶åˆ°main
git checkout main
git merge release/1.1.0

# 6. åˆ›å»ºæ ‡ç­¾
git tag -a v1.1.0 -m "Release version 1.1.0"

# 7. æ¨é€
git push origin main --tags

# 8. åˆå¹¶å›develop
git checkout develop
git merge main
git push origin develop
```

## ğŸ“¦ éƒ¨ç½²å’Œå‘å¸ƒ

### GitHub Actions
é¡¹ç›®ä½¿ç”¨GitHub Actionsè¿›è¡ŒCI/CDï¼š

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10", "3.11"]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Lint with flake8
      run: |
        flake8 src tests --count --select=E9,F63,F7,F82 --show-source --statistics
    
    - name: Test with pytest
      run: |
        pytest --cov=src --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
```

### ç‰ˆæœ¬ç®¡ç†
ä½¿ç”¨`semantic-release`è‡ªåŠ¨åŒ–ç‰ˆæœ¬ç®¡ç†ï¼š

```json
// package.json
{
  "release": {
    "branches": ["main"],
    "plugins": [
      "@semantic-release/commit-analyzer",
      "@semantic-release/release-notes-generator",
      "@semantic-release/changelog",
      "@semantic-release/github"
    ]
  }
}
```

## ğŸ§© æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„LLMæä¾›å•†
1. åœ¨`llm_analyzer.py`ä¸­æ·»åŠ æ–°çš„clientç±»
2. å®ç°æ ‡å‡†æ¥å£
3. æ›´æ–°é…ç½®æ”¯æŒ
4. æ·»åŠ æµ‹è¯•

### æ·»åŠ æ–°çš„æ•°æ®æº
1. åˆ›å»ºæ–°çš„fetcheræ¨¡å—
2. å®ç°ç»Ÿä¸€çš„æ•°æ®æ¥å£
3. æ›´æ–°æ•°æ®å¤„ç†æµç¨‹
4. æ·»åŠ é…ç½®é€‰é¡¹

### æ·»åŠ æ–°çš„åˆ†æåŠŸèƒ½
1. æ‰©å±•åˆ†ææç¤ºæ¨¡æ¿
2. æ›´æ–°åˆ†æç»“æœç»“æ„
3. æ·»åŠ æ–°çš„ç»Ÿè®¡æŒ‡æ ‡
4. æ›´æ–°å¯è§†åŒ–ç»„ä»¶

## ğŸ“š å­¦ä¹ èµ„æº

### Pythonå¼‚æ­¥ç¼–ç¨‹
- [Python asyncioå®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/library/asyncio.html)
- [Real Python: Async IO in Python](https://realpython.com/async-io-python/)

### æµ‹è¯•
- [pytestå®˜æ–¹æ–‡æ¡£](https://docs.pytest.org/)
- [Python Testing 101](https://realpython.com/python-testing/)

### ç±»å‹æç¤º
- [mypyå®˜æ–¹æ–‡æ¡£](https://mypy.readthedocs.io/)
- [Python Type Checking Guide](https://realpython.com/python-type-checking/)

---

è¿™ä¸ªå¼€å‘æŒ‡å—ä¼šæŒç»­æ›´æ–°ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡GitHub Issuesè”ç³»æˆ‘ä»¬ã€‚
