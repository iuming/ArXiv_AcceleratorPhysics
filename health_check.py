#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Project: ArXiv_AcceleratorPhysics
File: health_check.py
Author: Ming Liu
Email: ming-1018@foxmail.com
Institution: Institute of High Energy Physics, Chinese Academy of Sciences
Created: July 25th, 2025
Description: é¡¹ç›®å¥åº·çŠ¶æ€ç›‘æ§è„šæœ¬ï¼Œæ£€æŸ¥APIè¿æ¥ã€æ•°æ®å®Œæ•´æ€§ã€ç³»ç»ŸçŠ¶æ€ç­‰
             æä¾›å…¨é¢çš„ç³»ç»Ÿå¥åº·è¯Šæ–­å’Œé—®é¢˜æŠ¥å‘Š

Modification History:
- 2025-07-25: Initial creation
- 2025-07-25: Added comprehensive health monitoring
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import aiohttp
import yaml

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from utils import setup_logging

class HealthChecker:
    """ç³»ç»Ÿå¥åº·çŠ¶æ€æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.results = {}
        self.issues = []
        
    async def run_all_checks(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰å¥åº·æ£€æŸ¥"""
        self.logger.info("ğŸ¥ å¼€å§‹ç³»ç»Ÿå¥åº·æ£€æŸ¥...")
        
        checks = [
            ("ğŸ”‘ APIå¯†é’¥æ£€æŸ¥", self.check_api_keys),
            ("ğŸŒ ç½‘ç»œè¿æ¥æ£€æŸ¥", self.check_network_connectivity),
            ("ğŸ“ æ–‡ä»¶ç³»ç»Ÿæ£€æŸ¥", self.check_file_system),
            ("ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥", self.check_data_integrity),
            ("âš™ï¸ é…ç½®æ–‡ä»¶æ£€æŸ¥", self.check_configuration),
            ("ğŸ“¦ ä¾èµ–åŒ…æ£€æŸ¥", self.check_dependencies),
            ("ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡æ£€æŸ¥", self.check_performance_metrics),
            ("ğŸ”’ å®‰å…¨æ£€æŸ¥", self.check_security),
        ]
        
        for check_name, check_func in checks:
            try:
                self.logger.info(f"æ‰§è¡Œ {check_name}...")
                result = await check_func()
                self.results[check_name] = result
                if not result.get('status', True):
                    self.issues.append(f"{check_name}: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            except Exception as e:
                self.logger.error(f"{check_name} å¤±è´¥: {e}")
                self.results[check_name] = {'status': False, 'error': str(e)}
                self.issues.append(f"{check_name}: {str(e)}")
        
        # ç”Ÿæˆæ€»ä½“å¥åº·æŠ¥å‘Š
        overall_health = len(self.issues) == 0
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'overall_health': overall_health,
            'total_checks': len(checks),
            'passed_checks': len([r for r in self.results.values() if r.get('status', True)]),
            'failed_checks': len(self.issues),
            'issues': self.issues,
            'detailed_results': self.results,
            'recommendations': self.generate_recommendations()
        }
        
        self.logger.info(f"âœ… å¥åº·æ£€æŸ¥å®Œæˆã€‚æ€»ä½“çŠ¶æ€: {'å¥åº·' if overall_health else 'å­˜åœ¨é—®é¢˜'}")
        return report
    
    async def check_api_keys(self) -> Dict[str, Any]:
        """æ£€æŸ¥APIå¯†é’¥é…ç½®"""
        api_keys = {
            'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'),
            'DEEPSEEK_API_KEY': os.getenv('DEEPSEEK_API_KEY'),
            'HEPAI_API_KEY': os.getenv('HEPAI_API_KEY'),
            'ANTHROPIC_API_KEY': os.getenv('ANTHROPIC_API_KEY'),
        }
        
        configured_keys = {k: v for k, v in api_keys.items() if v}
        
        if not configured_keys:
            return {
                'status': False,
                'message': 'æ²¡æœ‰é…ç½®ä»»ä½•APIå¯†é’¥',
                'configured_keys': []
            }
        
        # æµ‹è¯•APIè¿æ¥
        working_keys = []
        for key_name, key_value in configured_keys.items():
            if await self._test_api_key(key_name, key_value):
                working_keys.append(key_name)
        
        status = len(working_keys) > 0
        return {
            'status': status,
            'message': f'é…ç½®äº† {len(configured_keys)} ä¸ªå¯†é’¥ï¼Œå…¶ä¸­ {len(working_keys)} ä¸ªå¯ç”¨',
            'configured_keys': list(configured_keys.keys()),
            'working_keys': working_keys
        }
    
    async def _test_api_key(self, key_name: str, key_value: str) -> bool:
        """æµ‹è¯•å•ä¸ªAPIå¯†é’¥"""
        try:
            if key_name == 'OPENAI_API_KEY':
                return await self._test_openai_key(key_value)
            elif key_name == 'DEEPSEEK_API_KEY':
                return await self._test_deepseek_key(key_value)
            # å¯ä»¥æ·»åŠ å…¶ä»–APIçš„æµ‹è¯•
            return True  # æš‚æ—¶è¿”å›True
        except:
            return False
    
    async def _test_openai_key(self, api_key: str) -> bool:
        """æµ‹è¯•OpenAI APIå¯†é’¥"""
        try:
            async with aiohttp.ClientSession() as session:
                headers = {'Authorization': f'Bearer {api_key}'}
                async with session.get(
                    'https://api.openai.com/v1/models',
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    return response.status == 200
        except:
            return False
    
    async def _test_deepseek_key(self, api_key: str) -> bool:
        """æµ‹è¯•DeepSeek APIå¯†é’¥"""
        try:
            async with aiohttp.ClientSession() as session:
                headers = {'Authorization': f'Bearer {api_key}'}
                async with session.get(
                    'https://api.deepseek.com/v1/models',
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    return response.status == 200
        except:
            return False
    
    async def check_network_connectivity(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç½‘ç»œè¿æ¥"""
        test_urls = [
            'https://export.arxiv.org/api/query',
            'https://api.openai.com',
            'https://api.deepseek.com',
            'https://github.com'
        ]
        
        working_connections = 0
        connection_details = {}
        
        async with aiohttp.ClientSession() as session:
            for url in test_urls:
                try:
                    start_time = datetime.now()
                    async with session.get(
                        url,
                        timeout=aiohttp.ClientTimeout(total=5)
                    ) as response:
                        response_time = (datetime.now() - start_time).total_seconds()
                        connection_details[url] = {
                            'status': 'ok',
                            'response_time': response_time,
                            'status_code': response.status
                        }
                        working_connections += 1
                except Exception as e:
                    connection_details[url] = {
                        'status': 'failed',
                        'error': str(e)
                    }
        
        status = working_connections >= len(test_urls) // 2  # è‡³å°‘ä¸€åŠçš„è¿æ¥æ­£å¸¸
        return {
            'status': status,
            'message': f'{working_connections}/{len(test_urls)} ä¸ªç½‘ç»œè¿æ¥æ­£å¸¸',
            'details': connection_details
        }
    
    async def check_file_system(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ–‡ä»¶ç³»ç»ŸçŠ¶æ€"""
        required_dirs = [
            'data',
            'data/papers',
            'data/analysis',
            'data/statistics',
            'logs',
            'config',
            'templates'
        ]
        
        missing_dirs = []
        for dir_path in required_dirs:
            if not Path(dir_path).exists():
                missing_dirs.append(dir_path)
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        disk_usage = self._get_disk_usage()
        
        # æ£€æŸ¥æ–‡ä»¶æƒé™
        permission_issues = self._check_file_permissions()
        
        status = len(missing_dirs) == 0 and disk_usage['free_gb'] > 1.0
        issues = []
        if missing_dirs:
            issues.append(f"ç¼ºå°‘ç›®å½•: {', '.join(missing_dirs)}")
        if disk_usage['free_gb'] < 1.0:
            issues.append(f"ç£ç›˜ç©ºé—´ä¸è¶³: å‰©ä½™ {disk_usage['free_gb']:.2f}GB")
        if permission_issues:
            issues.extend(permission_issues)
        
        return {
            'status': status,
            'message': 'æ–‡ä»¶ç³»ç»Ÿæ­£å¸¸' if status else '; '.join(issues),
            'missing_directories': missing_dirs,
            'disk_usage': disk_usage,
            'permission_issues': permission_issues
        }
    
    def _get_disk_usage(self) -> Dict[str, float]:
        """è·å–ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        import shutil
        
        try:
            total, used, free = shutil.disk_usage('.')
            return {
                'total_gb': total / (1024**3),
                'used_gb': used / (1024**3),
                'free_gb': free / (1024**3),
                'usage_percent': (used / total) * 100
            }
        except:
            return {'total_gb': 0, 'used_gb': 0, 'free_gb': 0, 'usage_percent': 100}
    
    def _check_file_permissions(self) -> List[str]:
        """æ£€æŸ¥æ–‡ä»¶æƒé™"""
        issues = []
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶çš„è¯»å†™æƒé™
        critical_paths = [
            'config/settings.yaml',
            'data',
            'logs'
        ]
        
        for path_str in critical_paths:
            path = Path(path_str)
            if path.exists():
                if not os.access(path, os.R_OK):
                    issues.append(f"æ— æ³•è¯»å– {path}")
                if path.is_dir() and not os.access(path, os.W_OK):
                    issues.append(f"æ— æ³•å†™å…¥ {path}")
        
        return issues
    
    async def check_data_integrity(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        data_issues = []
        
        # æ£€æŸ¥æœ€è¿‘å‡ å¤©çš„æ•°æ®
        for i in range(7):  # æ£€æŸ¥æœ€è¿‘7å¤©
            date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
            
            papers_file = Path(f'data/papers/{date}/papers.json')
            analysis_file = Path(f'data/analysis/{date}/analysis_results.json')
            
            if papers_file.exists():
                try:
                    with open(papers_file, 'r', encoding='utf-8') as f:
                        papers_data = json.load(f)
                    
                    if not isinstance(papers_data, list):
                        data_issues.append(f"{date}: è®ºæ–‡æ•°æ®æ ¼å¼é”™è¯¯")
                    elif len(papers_data) == 0:
                        data_issues.append(f"{date}: æ²¡æœ‰è®ºæ–‡æ•°æ®")
                    
                    # å¦‚æœæœ‰è®ºæ–‡æ•°æ®ä½†æ²¡æœ‰åˆ†æç»“æœ
                    if len(papers_data) > 0 and not analysis_file.exists():
                        data_issues.append(f"{date}: æœ‰è®ºæ–‡æ•°æ®ä½†ç¼ºå°‘åˆ†æç»“æœ")
                        
                except json.JSONDecodeError:
                    data_issues.append(f"{date}: è®ºæ–‡æ•°æ®JSONæ ¼å¼é”™è¯¯")
                except Exception as e:
                    data_issues.append(f"{date}: è¯»å–è®ºæ–‡æ•°æ®å¤±è´¥ - {e}")
        
        # æ£€æŸ¥ç»Ÿè®¡æ•°æ®
        stats_files = [
            'data/statistics/overall_stats.json',
            'data/statistics/category_distribution.json'
        ]
        
        for stats_file in stats_files:
            if not Path(stats_file).exists():
                data_issues.append(f"ç¼ºå°‘ç»Ÿè®¡æ–‡ä»¶: {stats_file}")
        
        status = len(data_issues) == 0
        return {
            'status': status,
            'message': 'æ•°æ®å®Œæ•´æ€§æ­£å¸¸' if status else f'å‘ç° {len(data_issues)} ä¸ªæ•°æ®é—®é¢˜',
            'issues': data_issues
        }
    
    async def check_configuration(self) -> Dict[str, Any]:
        """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
        config_issues = []
        
        # æ£€æŸ¥ä¸»é…ç½®æ–‡ä»¶
        config_file = Path('config/settings.yaml')
        if not config_file.exists():
            config_issues.append('ä¸»é…ç½®æ–‡ä»¶ä¸å­˜åœ¨')
        else:
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
                required_sections = ['arxiv', 'llm', 'storage']
                for section in required_sections:
                    if section not in config:
                        config_issues.append(f'é…ç½®ç¼ºå°‘ {section} éƒ¨åˆ†')
                
                # æ£€æŸ¥å…·ä½“é…ç½®
                if 'arxiv' in config:
                    if config['arxiv'].get('max_papers_per_day', 0) <= 0:
                        config_issues.append('max_papers_per_day é…ç½®æ— æ•ˆ')
                
            except yaml.YAMLError:
                config_issues.append('é…ç½®æ–‡ä»¶YAMLæ ¼å¼é”™è¯¯')
            except Exception as e:
                config_issues.append(f'è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}')
        
        # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶
        template_files = [
            'templates/analysis_prompt.txt',
            'templates/classification_prompt.txt'
        ]
        
        for template_file in template_files:
            if not Path(template_file).exists():
                config_issues.append(f'æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_file}')
        
        status = len(config_issues) == 0
        return {
            'status': status,
            'message': 'é…ç½®æ­£å¸¸' if status else f'å‘ç° {len(config_issues)} ä¸ªé…ç½®é—®é¢˜',
            'issues': config_issues
        }
    
    async def check_dependencies(self) -> Dict[str, Any]:
        """æ£€æŸ¥ä¾èµ–åŒ…"""
        import pkg_resources
        import subprocess
        
        missing_packages = []
        outdated_packages = []
        
        # è¯»å–requirements.txt
        try:
            with open('requirements.txt', 'r') as f:
                requirements = f.read().splitlines()
            
            for requirement in requirements:
                if requirement.strip() and not requirement.startswith('#'):
                    package_name = requirement.split('>=')[0].split('==')[0].strip()
                    try:
                        pkg_resources.get_distribution(package_name)
                    except pkg_resources.DistributionNotFound:
                        missing_packages.append(package_name)
        
        except FileNotFoundError:
            missing_packages.append('requirements.txtä¸å­˜åœ¨')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯æ›´æ–°çš„åŒ…
        try:
            result = subprocess.run(
                [sys.executable, '-m', 'pip', 'list', '--outdated', '--format=json'],
                capture_output=True, text=True, timeout=30
            )
            if result.returncode == 0:
                outdated = json.loads(result.stdout)
                outdated_packages = [pkg['name'] for pkg in outdated]
        except:
            pass  # å¿½ç•¥é”™è¯¯
        
        status = len(missing_packages) == 0
        return {
            'status': status,
            'message': f'ä¾èµ–æ£€æŸ¥å®Œæˆï¼Œç¼ºå°‘ {len(missing_packages)} ä¸ªåŒ…ï¼Œ{len(outdated_packages)} ä¸ªåŒ…å¯æ›´æ–°',
            'missing_packages': missing_packages,
            'outdated_packages': outdated_packages[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
        }
    
    async def check_performance_metrics(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡"""
        import psutil
        
        # ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°
        log_files = list(Path('logs').glob('*.log')) if Path('logs').exists() else []
        large_log_files = []
        
        for log_file in log_files:
            size_mb = log_file.stat().st_size / (1024 * 1024)
            if size_mb > 100:  # å¤§äº100MB
                large_log_files.append({'file': str(log_file), 'size_mb': size_mb})
        
        # æ£€æŸ¥æ•°æ®ç›®å½•å¤§å°
        data_size = self._get_directory_size('data') if Path('data').exists() else 0
        
        performance_issues = []
        if cpu_percent > 80:
            performance_issues.append(f'CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent}%')
        if memory.percent > 85:
            performance_issues.append(f'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent}%')
        if large_log_files:
            performance_issues.append(f'å‘ç° {len(large_log_files)} ä¸ªå¤§æ—¥å¿—æ–‡ä»¶')
        
        status = len(performance_issues) == 0
        return {
            'status': status,
            'message': 'æ€§èƒ½æ­£å¸¸' if status else f'å‘ç° {len(performance_issues)} ä¸ªæ€§èƒ½é—®é¢˜',
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'data_size_mb': data_size / (1024 * 1024),
            'large_log_files': large_log_files,
            'issues': performance_issues
        }
    
    def _get_directory_size(self, path: str) -> int:
        """è·å–ç›®å½•å¤§å°"""
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(filepath)
                except:
                    pass
        return total_size
    
    async def check_security(self) -> Dict[str, Any]:
        """å®‰å…¨æ£€æŸ¥"""
        security_issues = []
        
        # æ£€æŸ¥æ•æ„Ÿæ–‡ä»¶æƒé™
        sensitive_files = [
            'config/settings.yaml',
            '.env',
            '.env.local'
        ]
        
        for file_path in sensitive_files:
            path = Path(file_path)
            if path.exists():
                # åœ¨Unixç³»ç»Ÿä¸Šæ£€æŸ¥æ–‡ä»¶æƒé™
                if hasattr(os, 'stat') and hasattr(os.stat(file_path), 'st_mode'):
                    mode = oct(os.stat(file_path).st_mode)[-3:]
                    if mode != '600' and mode != '644':
                        security_issues.append(f'{file_path} æƒé™è¿‡äºå®½æ¾: {mode}')
        
        # æ£€æŸ¥æ˜¯å¦æ„å¤–æäº¤äº†æ•æ„Ÿä¿¡æ¯
        gitignore_path = Path('.gitignore')
        if gitignore_path.exists():
            with open(gitignore_path, 'r') as f:
                gitignore_content = f.read()
            
            sensitive_patterns = ['.env', '*.key', 'secrets.yaml']
            missing_patterns = [p for p in sensitive_patterns if p not in gitignore_content]
            
            if missing_patterns:
                security_issues.append(f'.gitignoreç¼ºå°‘æ•æ„Ÿæ–‡ä»¶æ¨¡å¼: {", ".join(missing_patterns)}')
        
        # æ£€æŸ¥é»˜è®¤å¯†ç æˆ–APIå¯†é’¥
        default_patterns = ['sk-test', 'your-api-key', 'changeme', 'default']
        for env_var in os.environ:
            if 'API_KEY' in env_var or 'TOKEN' in env_var or 'SECRET' in env_var:
                value = os.environ[env_var].lower()
                for pattern in default_patterns:
                    if pattern in value:
                        security_issues.append(f'ç¯å¢ƒå˜é‡ {env_var} å¯èƒ½ä½¿ç”¨äº†é»˜è®¤å€¼')
        
        status = len(security_issues) == 0
        return {
            'status': status,
            'message': 'å®‰å…¨æ£€æŸ¥é€šè¿‡' if status else f'å‘ç° {len(security_issues)} ä¸ªå®‰å…¨é—®é¢˜',
            'issues': security_issues
        }
    
    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºæ£€æŸ¥ç»“æœç”Ÿæˆå»ºè®®
        for check_name, result in self.results.items():
            if not result.get('status', True):
                if 'APIå¯†é’¥' in check_name:
                    recommendations.append('é…ç½®è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„LLM APIå¯†é’¥')
                elif 'ç½‘ç»œè¿æ¥' in check_name:
                    recommendations.append('æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®')
                elif 'æ–‡ä»¶ç³»ç»Ÿ' in check_name:
                    recommendations.append('ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨ä¸”æœ‰é€‚å½“æƒé™')
                elif 'æ•°æ®å®Œæ•´æ€§' in check_name:
                    recommendations.append('æ£€æŸ¥æ•°æ®å¤„ç†æµç¨‹å’Œé”™è¯¯å¤„ç†')
                elif 'é…ç½®æ–‡ä»¶' in check_name:
                    recommendations.append('éªŒè¯é…ç½®æ–‡ä»¶æ ¼å¼å’Œå¿…è¦è®¾ç½®')
                elif 'ä¾èµ–åŒ…' in check_name:
                    recommendations.append('è¿è¡Œ pip install -r requirements.txt')
                elif 'æ€§èƒ½' in check_name:
                    recommendations.append('è€ƒè™‘æ¸…ç†æ—¥å¿—æ–‡ä»¶å’Œä¼˜åŒ–ç³»ç»Ÿèµ„æº')
                elif 'å®‰å…¨' in check_name:
                    recommendations.append('å®¡æŸ¥æ–‡ä»¶æƒé™å’Œæ•æ„Ÿä¿¡æ¯ä¿æŠ¤')
        
        # é€šç”¨å»ºè®®
        if not recommendations:
            recommendations.append('ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå»ºè®®å®šæœŸè¿è¡Œå¥åº·æ£€æŸ¥')
        
        return recommendations[:5]  # é™åˆ¶å»ºè®®æ•°é‡

async def main():
    """ä¸»å‡½æ•°"""
    logger = setup_logging()
    
    try:
        checker = HealthChecker()
        report = await checker.run_all_checks()
        
        # ä¿å­˜æŠ¥å‘Š
        report_dir = Path('logs/health_reports')
        report_dir.mkdir(exist_ok=True)
        
        report_file = report_dir / f"health_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # è¾“å‡ºæ‘˜è¦
        print(f"\n{'='*60}")
        print(f"ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        print(f"æ€»ä½“çŠ¶æ€: {'âœ… å¥åº·' if report['overall_health'] else 'âŒ å­˜åœ¨é—®é¢˜'}")
        print(f"æ£€æŸ¥é¡¹ç›®: {report['passed_checks']}/{report['total_checks']} é€šè¿‡")
        
        if report['issues']:
            print(f"\nğŸš¨ å‘ç°çš„é—®é¢˜:")
            for issue in report['issues']:
                print(f"  â€¢ {issue}")
        
        if report['recommendations']:
            print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
            for rec in report['recommendations']:
                print(f"  â€¢ {rec}")
        
        print(f"\nğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print(f"{'='*60}")
        
        # å¦‚æœæœ‰é—®é¢˜ï¼Œä»¥éé›¶é€€å‡ºç é€€å‡º
        sys.exit(0 if report['overall_health'] else 1)
        
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
